#!/usr/bin/env python

import os
import sys
import time
from threading import Thread

try:
    from optparse import Option, OptionParser
    from gppylib.gpparseopts import OptParser, OptChecker
    from gppylib.gparray import GpArray
    from gppylib.gphostcache import *
    from gppylib.gplog import *
    from gppylib.commands.unix import *
    from gppylib.commands.gp import *
    from gppylib.db import dbconn
    from gppylib.userinput import *
    from pygresql.pg import DatabaseError
    from gppylib.gpcoverage import GpCoverage
except ImportError, e:
    sys.exit('Cannot import modules.  Please check that you have sourced greenplum_path.sh.  Detail: ' + str(e))

EXECNAME = os.path.split(__file__)[-1]

def parseargs():

    parser = OptParser(option_class=OptChecker)
    parser.remove_option('-h')
    parser.add_option('-h', '-?', '--help', action='help')
    parser.add_option('-v','--verbose', action='store_true')
    parser.add_option('--debug', action='store_true')
    parser.add_option('-d','--database', type='string')
    (options, args) = parser.parse_args()

    USER=os.getenv('USER')
    if USER is None or USER is ' ':
        logger.error('USER environment variable must be set.')
        parser.exit()

    if options.database is None:
        options.database = os.environ.get('PGDATABASE', 'template1')

    return options

class integrity_query:

    def __init__(self,schema,name):
        self.query = "COPY %s.%s TO '/dev/null'" % (schema,name)

class tables_query:
    def __init__(self):
        self.query = "SELECT n.nspname, c.relname from pg_class c join pg_namespace n on c.relnamespace = n.oid where c.relkind = 'r' and relstorage != 'x' and n.nspname != 'pg_catalog' and c.relhassubclass='f'"

def userConfirm():
    if not ask_yesno('', "Are you sure you want to ignore unreachable hosts?",'N'):
        logger.info("User Aborted. Exiting...")
        sys.exit(0)

class Check_Integrity(Thread):
    def __init__(self, tables, hostname, database,content, port):
        Thread.__init__(self)
        self.hostname = hostname
        self.database = database
        self.port = port
        self.content = content
        self.tables = tables

    def run(self):
        for table in self.tables:
            try:
                logger.info("[seg%s] Checking table %s.%s" % (self.content,table[0],table[1]))
                my_conn = dbconn.DbURL(dbname=self.database,hostname=self.hostname,port=self.port)
                my2_conn = dbconn.connect(my_conn, True)
                dbconn.execSQL(my2_conn,integrity_query(table[0],table[1]).query)

            except DatabaseError:
                    logger.error('Failed for table %s.%s at seg%s' % (table[0],table[1],self.content))
                    #TODO: pygresql wraps all queries in the same cursor under the same transaction. If one query fail, transaction is aborted.
                    my2_conn.close()
                    my2_conn = dbconn.connect(dburl,True)
            my2_conn.close()





#------------------------------- Mainline --------------------------------

coverage = GpCoverage()
coverage.start()

logger = get_default_logger()
setup_tool_logging(EXECNAME,getLocalHostname(),getUserName())

options = parseargs()
logger.info("Checking integrity of database %s" % options.database)
if not ask_yesno('', "Are you sure you want to check integrity of database %s?" % options.database,'N'):
    logger.info("User Aborted. Exiting...")
    sys.exit(0)


if options.verbose:
    enable_verbose_logging()

try:
    dburl = dbconn.DbURL()
    gparray = GpArray.initFromCatalog(dburl,utility=True)

except DatabaseError, ex:
    logger.error(ex.__str__())
    logger.error('Failed to connect to database, exiting without action. This script can only be run when the database is up.')
    sys.exit(1)

pool = WorkerPool()
hostCache = GpHostCache(gparray, pool)
failedPings = hostCache.ping_hosts(pool)

if len(failedPings):
    for i in failedPings:
        logger.warning('unreachable host: ' + i.hostname)
    userConfirm()

try:
    # get table list
    dburl = dbconn.DbURL(dbname=options.database)
    conn = dbconn.connect(dburl, True)
    tables = list(dbconn.execSQL(conn,tables_query().query))
    conn.close()

    threads= []

    # do the segments
    for h in hostCache.get_hosts():
        for seg in h.dbs:
            #TODO: Only checks preferred role
            if seg.isSegmentPrimary():
                th = Check_Integrity(tables,seg.hostname,options.database,seg.content,seg.port)
                th.start()
                threads.append(th)

    for thread in threads:
        logger.debug('waiting on thread %s' % thread.getName())
        thread.join()
        logger.debug('thread ok')

    pool.join()
    items = pool.getCompletedItems()
    failure = False
    for i in items:
        if not i.was_successful():
            # TODO: When does the query fail and when does the connection fail
            logger.error('failed checking integrity on host: ' + i.remoteHost)
            failure = True

    pool.check_results()
#TODO: Better exception handling
except Exception, e:
    logger.error('errors in job:')
    logger.error(e.__str__())
    logger.error('exiting early')

pool.haltWork()
pool.joinWorkers()


logger.info("completed successfully")

coverage.stop()
coverage.generate_report()
