#!/usr/bin/env python

import os
import string
import sys
from threading import Thread, Lock

try:
    from optparse import Option, OptionParser
    from gppylib.gpparseopts import OptParser, OptChecker
    from gppylib.gparray import GpArray
    from gppylib.gphostcache import *
    from gppylib.gplog import *
    from gppylib.commands.unix import *
    from gppylib.commands.gp import *
    from gppylib.db import dbconn
    from gppylib.userinput import *
    from pygresql.pg import DatabaseError
    from gppylib.gpcoverage import GpCoverage
    from pygresql.pgdb import DatabaseError
    from pygresql import pg
    from datetime import datetime

except ImportError, e:
    sys.exit('Cannot import modules.  Please check that you have sourced greenplum_path.sh.  Detail: ' + str(e))

##############
EXECNAME = os.path.split(__file__)[-1]
setup_tool_logging(EXECNAME,getLocalHostname(),getUserName())
logger = get_default_logger()
##############


def print_help(option, opt, value, parser):
    # This function signature is mandatory as this is a callback for OptionParse
    # even if we only use :param parser:
    print("""
COMMAND NAME: gpcheckintegrity

*****************************************************
SYNOPSIS
*****************************************************

gpcheckintegrity [-v | --verbose] [-s | --schema <schema_name> ] -d | --database <database>

gpcheckintegrity -h | -? | --help

*****************************************************
DESCRIPTION
*****************************************************

Utility for Greenplum Database that performs a table integrity exam to verify that all the
tables in a specific database can be queried.

***********************************
OPTIONS
***********************************

-v | --verbose

    Enables extra debug output. Only useful for debugging the tool itself.

-s | --schema <schema_name>

    Schema name to fetch the tables from. If this option is set, gpcheckintegrity
    will limit the integrity check to the tables located in this schema

-d | --database <database>

    Name of the database to check. This option is mandatory

-h | -? | --help

    Prints this help page

*****************************************************
EXAMPLES
*****************************************************

Check the integrity of all the tables in the database 'sales':

gpcheckintegrity -d sales


Check the integrity of all the tables in 'division_1' from DB 'sales':

gpcheckintegrity -s division_1 -d sales


Display this message again:

gpcheckintegrity -h

*****************************************************
BUGS
*****************************************************

Please report any bugs in https://github.com/ielizaga/gpcheckintegrity
""")
    parser.exit()


def parseargs():
    # TODO: use global class to keep some variables present at all times
    parser = OptParser(option_class=OptChecker)
    parser.remove_option('-h')
    parser.add_option('-h', '-?', '--help', action="callback", callback=print_help)
    parser.add_option('-v', '--verbose', action='store_true')
    parser.add_option('-s', '--schema', type='string')
    parser.add_option('-S', '--schema-list', type='string', dest='schema_list')
    # TODO: perform check for multiple databases
    parser.add_option('-d', '--database', type='string')
    (options, args) = parser.parse_args()

    USER = os.getenv('USER')
    if USER is None or USER is ' ':
        logger.error('USER environment variable must be set.')
        parser.exit()

    if options.database is None:
        logger.error('Database must be specified.')
        parser.exit()

    return options


def connect(user=None, password=None, host=None, port=None, database=None, utilityMode=False):
    conf = utilityMode and '-c gp_session_role=utility' or None
    if not user:
        user = os.environ.get('PGUSER')
    if not user:
        user = os.environ.get('USER')
    if not password:
        password = os.environ.get('PGPASSWORD')
    if not host:
        host = 'localhost'
    if not port:
        port = os.environ.get('PGPORT', 5432)
    if not database:
        database = os.environ.get('PGDATABASE', 'template1')
    try:
        logger.debug('connecting to %s:%s %s' % (host, port, database))
        db = pg.connect(host=host, port=port, user=user,
                        passwd=password, dbname=database, opt=conf)
    except pg.InternalError, ex:
        logger.fatal('could not connect to %s: "%s"' %
                     (database, str(ex).strip()))
        exit(1)

    logger.debug('connected with %s:%s %s' % (host, port, database))
    return db


def get_gp_segment_configuration(database=None):
    cfg = {}
    db = connect(database=database)

    qry = '''
          SELECT content, preferred_role = 'p' as definedprimary,
                 dbid, role = 'p' as isprimary, hostname, address, port,
                 fselocation as datadir
            FROM gp_segment_configuration JOIN pg_filespace_entry on (dbid = fsedbid)
           WHERE fsefsoid = (select oid from pg_filespace where fsname='pg_system')
             AND (role = 'p' or content < 0 )
          '''
    curs = db.query(qry)
    for row in curs.dictresult():
        if row['content'] == -1:
            continue  # skip master
        cfg[row['dbid']] = row
    db.close()
    return cfg


def get_tables(database=None):
    db = connect(database=database)
    table_list = []

    # Retrieve all non-catalog/non partitioned parent tables
    qry = '''
          SELECT n.nspname as schema, c.relname as table
            FROM pg_class c join pg_namespace n ON (c.relnamespace = n.oid)
           WHERE (c.relkind = 'r') and (relstorage != 'x') and (n.nspname != 'pg_catalog') and (c.relhassubclass='f')
          '''
    curs = db.query(qry)
    for row in curs.dictresult():
        table_list.append(row)
    db.close()
    return table_list


def get_tables_in_schema(database, schema):
    """
    This function returns a list of tables within :param schema:. If the schema is pg_catalog, it returns None and
    logs an error.
    :param database: name of the database
    :param schema: schema to fetch table names from
    :return: list of tables or None if :param schema: is 'pg_catalog'
    :raise ValueError: if schema is 'pg_catalog'
    """
    db = connect(database=database)
    table_list = []

    if schema == "pg_catalog":
        logger.error("This check is ineffective on catalog tables. Use gpcheckcat to check catalog integrity")
        raise ValueError("Schema is pg_catalog")

    # Retrieve all non-catalog/non partitioned parent tables
    qry = '''
          SELECT n.nspname as schema, c.relname as table
            FROM pg_class c join pg_namespace n ON (c.relnamespace = n.oid)
           WHERE (c.relkind = 'r') and (relstorage != 'x') and (n.nspname = '%s') and (c.relhassubclass='f')
          ''' % pg.escape_string(schema)
    curs = db.query(qry)

    for row in curs.dictresult():
        table_list.append(row)

    db.close()

    return table_list


def database_schema_exists(database, schema):

    db = connect(database=database)
    qry = '''
    select True as exists from pg_namespace a where a.nspname = '%s'
    ''' % pg.escape_string(schema)

    logger.debug("Running query: %s" % qry)

    curs = db.query(qry)

    return curs.ntuples() == 1


class CheckIntegrity(Thread):
    def __init__(self, tables, hostname, database, content, port):
        Thread.__init__(self)
        self.hostname = hostname
        self.database = database
        self.port = port
        self.content = content
        self.tables = tables

    def run(self):
        db = connect(database=self.database, host=self.hostname, port=self.port, utilityMode=True)
        for table in self.tables:
            try:
                logger.info("[seg%s] Checking table %s.%s" % (self.content, table['schema'], table['table']))
                qry = '''
                      COPY %s.%s
                      TO '/dev/null'
                      ''' % (table['schema'], table['table'])
                db.query(qry)
            except DatabaseError, de:
                # TODO: better error summary report
                logger.error('Failed for table %s.%s at seg%s' % (table['schema'], table['table'], self.content))
                logger.error('ERROR:%s' % str(de).strip())

                # Append this table name to reported_table list
                table_lock.acquire()
                reported_tables.append("%s.%s in %s:%d gpseg%s" % (table['schema'], table['table'],
                                                                   self.hostname, self.port, self.content))
                table_lock.release()

                # TODO: pygresql wraps all queries in the same cursor under the same transaction
                db.close()
                db = connect(database=self.database, host=self.hostname, port=self.port, utilityMode=True)
        db.close()


#############
if __name__ == '__main__':
    logger = get_default_logger()
    setup_tool_logging(EXECNAME, getLocalHostname(), getUserName())

    options = parseargs()
    logger.info("Checking integrity of database %s" % options.database)

    if options.verbose:
        enable_verbose_logging()

    try:
        # TODO: List number of databases/schemas/tables to be checked and prompt to continue
        dbids = get_gp_segment_configuration()  # get Greenplum segment information

        tables = list()

        if options.schema:
            tables = get_tables_in_schema(options.database, options.schema)
            logger.info("Checking only tables in schema %s" % options.schema)

        if options.schema_list and type(options.schema_list) is str:
            schemas = string.split(options.schema_list, ',')
            for s in schemas:
                if database_schema_exists(options.database, s):
                    tables.extend(get_tables_in_schema(options.database, s))
                else:
                    logger.warn("Schema %s not found" % s)

        if options.schema is None and options.schema_list is None:
            tables = get_tables(database=options.database)  # get table list

        threads = []
        reported_tables = []
        table_lock = Lock()

        for dbid in dbids:
            if dbids[dbid]['isprimary'] == 't':
                th = CheckIntegrity(tables, dbids[dbid]['hostname'], options.database, dbids[dbid]['content'],
                                     dbids[dbid]['port'])
                th.start()
                threads.append(th)

        for thread in threads:
            logger.debug('waiting on thread %s' % thread.getName())
            thread.join()

        logger.info("REPORT SUMMARY %s" % datetime.now())
        logger.info("============================================")

        if len(reported_tables) == 0:
            logger.info("No tables reported inconsistency errors")
        else:
            for t in reported_tables:
                logger.info(t)

    # TODO: Better exception handling
    except Exception, e:
        logger.error('errors in job:')
        logger.error(e.__str__())
        logger.error('exiting early')

    logger.info("completed successfully")

